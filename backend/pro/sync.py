import sqlglot
from sqlglot import diff, transpile, parse_one, exp
from sqlalchemy import inspect
from database import get_engine
from models import ConnectionConfig

def get_dialect(conn_type: str) -> str:
    mapping = {
        'postgresql': 'postgres',
        'mysql': 'mysql',
        'sqlite': 'sqlite',
        'mssql': 'tsql',
        'oracle': 'oracle'
    }
    return mapping.get(conn_type, 'sqlite')

def reflect_schema_to_sql(engine, dialect: str) -> str:
    """
    Reflects the database schema and generates a sequence of CREATE TABLE statements.
    """
    inspector = inspect(engine)
    ddl_statements = []
    
    for table_name in inspector.get_table_names():
        columns = inspector.get_columns(table_name)
        pk_constraint = inspector.get_pk_constraint(table_name)
        pks = pk_constraint.get('constrained_columns', [])
        
        column_defs = []
        for c in columns:
            col_name = c['name']
            col_type = str(c['type'])
            nullable = "NULL" if c.get('nullable', True) else "NOT NULL"
            default = f"DEFAULT {c['default']}" if c.get('default') is not None else ""
            
            # Simple column definition
            col_def = f"{col_name} {col_type} {nullable} {default}".strip()
            column_defs.append(col_def)
        
        if pks:
            column_defs.append(f"PRIMARY KEY ({', '.join(pks)})")
            
        column_defs_str = ",\n  ".join(column_defs)
        create_table = f"CREATE TABLE {table_name} (\n  {column_defs_str}\n);"
        ddl_statements.append(create_table)
        
    return "\n\n".join(ddl_statements)

def diff_schemas(source_config: ConnectionConfig, target_config: ConnectionConfig) -> str:
    """
    Compares two schemas and returns SQL statements to migrate target to source.
    """
    try:
        source_engine = get_engine(source_config)
        target_engine = get_engine(target_config)
        
        source_dialect = get_dialect(source_config.type)
        target_dialect = get_dialect(target_config.type)
        
        source_ddl = reflect_schema_to_sql(source_engine, source_dialect)
        target_ddl = reflect_schema_to_sql(target_engine, target_dialect)
        
        if not source_ddl:
            return "-- Source database is empty."
            
        # Parse DDL into sqlglot expressions
        source_expressions = sqlglot.parse(source_ddl, read=source_dialect)
        target_expressions = sqlglot.parse(target_ddl, read=target_dialect)
        
        # In a real implementation, we would compare individual table expressions.
        # For this version, we provide the transpilated source DDL if target is different.
        
        diff_output = [
            f"-- Migration from {source_config.name} ({source_config.type}) to {target_config.name} ({target_config.type})",
            f"-- Generated by SqlForge AI Engine",
            ""
        ]
        
        if source_ddl == target_ddl:
            return "-- Schemas are identical."

        # Transpile source schema to target dialect
        transpiled_ddl = transpile(source_ddl, read=source_dialect, write=target_dialect, pretty=True)
        
        diff_output.append("-- Suggested schema for target database:")
        diff_output.extend(transpiled_ddl)
        
        return "\n".join(diff_output)
        
    except Exception as e:
        return f"-- Error generating schema diff: {str(e)}"

def sync_schemas(source_config: ConnectionConfig, target_config: ConnectionConfig, dry_run: bool = True):
    """
    Execute the sync process.
    """
    sql = diff_schemas(source_config, target_config)
    if dry_run:
        return {"status": "success", "message": "Dry run completed", "sql": sql}
    
    # Execution logic would go here
    return {"status": "pending", "message": "Schema synchronization execution is a Pro-only automated feature.", "sql": sql}
