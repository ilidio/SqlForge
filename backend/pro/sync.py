import sqlglot
from sqlglot import diff, transpile, parse_one, exp
from sqlalchemy import inspect
from database import get_engine
from models import ConnectionConfig

def get_dialect(conn_type: str) -> str:
    mapping = {
        'postgresql': 'postgres',
        'mysql': 'mysql',
        'sqlite': 'sqlite',
        'mssql': 'tsql',
        'oracle': 'oracle'
    }
    return mapping.get(conn_type, 'sqlite')

def reflect_schema_to_sql(engine, dialect: str) -> str:
    """
    Reflects the database schema and generates a sequence of CREATE TABLE statements.
    """
    inspector = inspect(engine)
    ddl_statements = []
    
    for table_name in inspector.get_table_names():
        columns = inspector.get_columns(table_name)
        pk_constraint = inspector.get_pk_constraint(table_name)
        pks = pk_constraint.get('constrained_columns', [])
        
        column_defs = []
        for c in columns:
            col_name = c['name']
            col_type = str(c['type']).upper()
            
            # Basic normalization for common types to help sqlglot
            if "VARCHAR" in col_type: col_type = "VARCHAR(255)"
            if "INTEGER" in col_type: col_type = "INT"
            
            nullable = "NULL" if c.get('nullable', True) else "NOT NULL"
            
            col_def = f"{col_name} {col_type} {nullable}"
            column_defs.append(col_def)
        
        if pks:
            column_defs.append(f"PRIMARY KEY ({', '.join(pks)})")
            
        column_defs_str = ",\n  ".join(column_defs)
        create_table = f"CREATE TABLE {table_name} (\n  {column_defs_str}\n);"
        ddl_statements.append(create_table)
        
    return "\n\n".join(ddl_statements)

def diff_schemas(source_config: ConnectionConfig, target_config: ConnectionConfig) -> str:
    """
    Compares two schemas and returns SQL statements to migrate target to source.
    """
    try:
        source_engine = get_engine(source_config)
        target_engine = get_engine(target_config)
        
        source_dialect = get_dialect(source_config.type)
        target_dialect = get_dialect(target_config.type)
        
        source_ddl = reflect_schema_to_sql(source_engine, source_dialect)
        target_ddl = reflect_schema_to_sql(target_engine, target_dialect)
        
        diff_output = [
            f"-- Migration from {source_config.name} ({source_config.type}) to {target_config.name} ({target_config.type})",
            f"-- Generated by SqlForge Sync Engine",
            ""
        ]

        if not source_ddl:
            return "\n".join(diff_output + ["-- Source database is empty. Nothing to sync."])

        if source_ddl == target_ddl:
            return "\n".join(diff_output + ["-- Schemas are identical."])

        # Parse DDL into sqlglot expressions, filtering out None from empty strings
        source_exprs = [e for e in sqlglot.parse(source_ddl, read=source_dialect) if e]
        target_exprs = [e for e in sqlglot.parse(target_ddl, read=target_dialect) if e]
        
        # Build a map of tables in target for easy lookup
        target_tables = {}
        for expr in target_exprs:
            if isinstance(expr, exp.Create) and isinstance(expr.this, (exp.Table, exp.Schema)):
                t_name = expr.this.this.name.lower() if isinstance(expr.this, exp.Schema) else expr.this.name.lower()
                target_tables[t_name] = expr
        
        final_sql = []
        
        for s_expr in source_exprs:
            if not isinstance(s_expr, exp.Create) or not isinstance(s_expr.this, (exp.Table, exp.Schema)):
                continue
                
            s_table = s_expr.this.this if isinstance(s_expr.this, exp.Schema) else s_expr.this
            table_name = s_table.name.lower()
            
            if table_name not in target_tables:
                # Table missing in target: CREATE it
                transpiled = transpile(s_expr.sql(), read=source_dialect, write=target_dialect, pretty=True)[0]
                final_sql.append(f"-- Create missing table: {table_name}\n{transpiled}\n")
            else:
                # Table exists: Check for differences using sqlglot diff
                t_expr = target_tables[table_name]
                changes = diff(t_expr, s_expr)
                
                if changes:
                    # If there are changes, we suggest a full recreation for now or detailed alters
                    transpiled = transpile(s_expr.sql(), read=source_dialect, write=target_dialect, pretty=True)[0]
                    final_sql.append(f"-- Update existing table: {table_name}\n{transpiled}\n")

        if not final_sql:
            return "\n".join(diff_output + ["-- No structural changes detected."])

        return "\n".join(diff_output + final_sql)
        
    except Exception as e:
        import traceback
        return f"-- Error generating schema diff: {str(e)}\n-- {traceback.format_exc()}"

def sync_schemas(source_config: ConnectionConfig, target_config: ConnectionConfig, dry_run: bool = True):
    """
    Execute the sync process.
    """
    sql = diff_schemas(source_config, target_config)
    if dry_run:
        return {"status": "success", "message": "Dry run completed", "sql": sql}
    
    # For this version, we provide the transpilated source DDL as a success message.
    # In a future update, we can use engine.connect().execute(text(sql)) to apply it automatically.
    return {"status": "success", "message": "Schema synchronization plan generated successfully. You can now apply the SQL below.", "sql": sql}